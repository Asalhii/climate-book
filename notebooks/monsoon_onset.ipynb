{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbada676",
   "metadata": {},
   "source": [
    "## **Monsoon Onset**\n",
    "\n",
    "In this module we are going to use the onset index of [Walker and Bordoni (2016)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016GL071026), hereafter WB16.\n",
    "\n",
    "Let's start by taking a look at the IMD onset monitoring from 2024.\n",
    "\n",
    "<img src=\"https://mausam.imd.gov.in/ClimateInformation/imdweb/DAY_WEEK/onset_SW.gif\" width=500 />\n",
    "\n",
    "We notice that the monsoon progresses northwestward and thus the *local* onset of rains is latitude dependent.\n",
    "Keeping this in mind, in this paper we will be attempting to derive a mean onset date for all-India. \n",
    "\n",
    "Let's start by looking at the mean precipitation for the box 10–30°N, 60–100°E, a large region that encompasses the Indian subcontinent and is frequently used domain for the South Asian summer Monsoon (SASM). We will simply use ERA5 here.  You will learn how to make this plot later...\n",
    "\n",
    "<img src=\"images/ERA5_precip_2000.jpg\" width=\"500\" />\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## **Discussion**\n",
    "\n",
    "Break out into groups and quickly discuss these questions.\n",
    "\n",
    "- Does the plot based on ERA5 resemble the paper plot using MERRA/GPCP?\n",
    "- Look at the precipation graph, roughly at what day would you define the monsoon onset?\n",
    "- What are the difficulties of using this field to define the onset?\n",
    "- If you were to use a threshold rainfall event, how would you set it?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993706e-8986-420c-9b27-c93a0ab5a30c",
   "metadata": {},
   "source": [
    "### The Walker-Bordoni onset index\n",
    "\n",
    "The key concept of this paper is that rather than assessing the onset date for the monsoon based directly on the precipitation, it instead employed the large scale column water budget, which constrains net precipitation. This builds on Walker et al. 2015, who used a similar index for interannual variability.   \n",
    "\n",
    "For a given region, we can write an equation for the rate of change of the total column water vapor $W$ (sometimes referred to as the \"precipitable water\", or referred to as TCWV in ECMWF grib table 128),  which is defined as $ W = \\int ^0_{p_0} q_v \\frac{dp}{g}$.  \n",
    "\n",
    "The rate of change of $W$ is simply a sum of the atmospheric sources and sinks:\n",
    "\n",
    "$$ \\frac{\\partial W}{\\partial t} = MFC - P + E $$\n",
    "\n",
    "where $P$ is precipitation, $E$ total surface evaporation, and $MFC$ is the moisture flux convergence, given by\n",
    "\n",
    "$$ MFC = - \\int^{p_s}_{0} \\nabla . (u q_v) \\frac{dp}{g} $$ \n",
    "\n",
    "where $u$ is the horizontal wind vector and $q_v$ is the specific humidity.\n",
    "\n",
    "They show these terms in their Figure 1 for the year 2000, (panel a) for the region 10–30°N, 60–100°E, a large region that encompasses the Indian subcontinent and is frequently used domain for the South Asian summer Monsoon (SASM). Remember, each of these terms is calculated as an *area average*.  SB16 use MERRA reanalysis combined with GPCP for precipitation. \n",
    "\n",
    "Ignore the red line for now - we will explain what this is later on...\n",
    "\n",
    "\n",
    "<img src=\"images/SB16_fig1.jpg\" width=\"500\" height=\"300\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb674b57",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Discussion \n",
    "\n",
    "What are the key features of the precipitation, evaporation and storage?\n",
    "</div>\n",
    "\n",
    "What do we see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fadddb",
   "metadata": {},
   "source": [
    "- **Precipitation**:  The field is quite noisy in time, and starts to increase around day 150. \n",
    "\n",
    "- **Evaporation**: This exceeds the precipitation at the start of the year, when precipitation is essentially zero.  It increases in the rainy season as the soil moisture increases but the seasonal variation is much less than that of the precipitation. Note that we do not expect P~E over land averaged over time, why not?\n",
    "\n",
    "- **Storage**: The $\\frac{\\partial W}{\\partial t}$ storage term oscillates around zero; storage is not that important it seems! (This is not always so true for other monsoon systems).  Thus the divergence of water over the region is approximately in balance with $P-E$. In fact, as pointed out by WB16: *\"With negligible storage $\\frac{\\partial W}{\\partial t}$, the dominant balance in the SASM region is between MFC and net precipitation (P-E). Thus, positive (negative) values of MFC correspond to positive (negative) net precipitation.\"*\n",
    "\n",
    "We will now examine these timeseries, trying to recreate this plot using ERA5 reanalysis data. \n",
    "\n",
    "If you are not familiar with netcdf file formats or the command line tool cdo ([climate data operators](https://code.mpimet.mpg.de/projects/cdo)) we suggest you follow the video series of [ClimateUnboxed](https://www.youtube.com/@climateunboxed).  The following box would allow you to download the data to your laptop and calculate the box averages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c6762e-2563-49ce-a46f-d4d1c89cdd7f",
   "metadata": {},
   "source": [
    "On the Copernicus Climate Data store for ERA5, these are the names of the variables:\n",
    "\n",
    "\n",
    "| eqn               | long name                                     |  ECMWF name |\n",
    "|-------------------|-----------------------------------------------|-------------|\n",
    "| $P$               | total_precipitation                           |  tp         |\n",
    "| $E$               | evaporation                                   |  e          |\n",
    "| $\\frac{\\partial W}{\\partial t}$ | vertical_integeration_of_moisture_divergence | VIMD  |\n",
    "\n",
    "\n",
    "\n",
    "VIMD is available from the reanalysis, but is usually not saved as a forecast product. We will return to this in the exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc601f5d-5281-405f-b9df-55ad775eceed",
   "metadata": {},
   "source": [
    "But before we start let's just import a few packages we will be needing and show you how to install others if any of them are missing in the box below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e651911a-cb4f-4ea8-b03c-50e875b38e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23007bec-b023-408e-ab02-6e6f76a8ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# you ONLY need these packages if you want to download the data yourself... \n",
    "# Uncomment these lines if so \n",
    "#\n",
    "### import cdsapi\n",
    "### from cdo import Cdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28e3abce-0368-4c88-ae50-241eb8ad15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to install anything you can do it this way: uncomment the packages\n",
    "# you need and then you will need to restart your kernal\n",
    "\n",
    "#%pip install cdo\n",
    "#%pip install netCDF4\n",
    "#%pip install xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212367b-37e8-4b45-a124-bd05086ee3f9",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**NOTE**\n",
    "As the CDS is extremely slow at the moment, we prepared the timeseries data which can directly download using wget, or simply access directory online from the python netCDF4 utility, which is how this notebook operates\n",
    "</div>\n",
    " \n",
    "If you want to use the retrieve script later on, so you can change your data, you can watch the video tutorials on \"ClimateUnboxed\" and [see the instructions here](https://cds.climate.copernicus.eu/how-to-api) \n",
    "\n",
    "In this case set get_cds to True!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4148d03-c8d0-4a5c-b11f-e13704c6812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cds=False # we will use the pre-prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bad96e5c-5a24-4fc6-b7b5-74006b41d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This shows you how to get the data yourself if you want to have the files locally\n",
    "#\n",
    "if get_cds:\n",
    "    locdir=\"./\" # where you want to put the data\n",
    "\n",
    "    # make incidence \n",
    "    client=cdsapi.Client()\n",
    "    cdo=Cdo()\n",
    "    \n",
    "    # dataset we are using:\n",
    "    dataset = \"derived-era5-single-levels-daily-statistics\"\n",
    "    \n",
    "    for year in range(1961,1971):\n",
    "        for var in [\n",
    "            \"total_precipitation\",\n",
    "            \"evaporation\",\n",
    "            \"vertical_integral_of_divergence_of_moisture_flux\"\n",
    "        ]:\n",
    "            \n",
    "            request = {\n",
    "        \"product_type\": \"reanalysis\",\n",
    "                \"variable\": var,\n",
    "        \"year\": str(year),  # recall that the year needs to be a string!\n",
    "        \"month\": [\n",
    "            \"01\", \"02\", \"03\",\n",
    "            \"04\", \"05\", \"06\",\n",
    "            \"07\", \"08\", \"09\",\n",
    "            \"10\", \"11\", \"12\"\n",
    "        ],\n",
    "        \"day\": [\n",
    "            \"01\", \"02\", \"03\",\n",
    "            \"04\", \"05\", \"06\",\n",
    "            \"07\", \"08\", \"09\",\n",
    "            \"10\", \"11\", \"12\",\n",
    "            \"13\", \"14\", \"15\",\n",
    "            \"16\", \"17\", \"18\",\n",
    "            \"19\", \"20\", \"21\",\n",
    "            \"22\", \"23\", \"24\",\n",
    "            \"25\", \"26\", \"27\",\n",
    "            \"28\", \"29\", \"30\",\n",
    "            \"31\"\n",
    "        ],\n",
    "        \"daily_statistic\": \"daily_mean\",\n",
    "        \"time_zone\": \"utc+00:00\",\n",
    "                \"frequency\": \"1_hourly\",\n",
    "                \"area\": [60, -180, -40, 180]\n",
    "    }\n",
    "    \n",
    "            ifile=locdir+\"era5_daily_\"+str(year)+\"_\"+var+\".nc\"\n",
    "            ofile=locdir+\"era5_ts_\"+str(year)+\"_\"+var+\".nc\"\n",
    "            client.retrieve(dataset, request).download(ifile)\n",
    "            cdo.fldmean(input=\"-sellonlatbox,60,100,10,30 \"+ifile,output=ofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35398fee-8ad8-4752-9659-79f5e94be79e",
   "metadata": {},
   "source": [
    "**alternative shortcut - prepared online data**\n",
    "\n",
    "as the CDS has issues at the moment rendering it very slow, here we have prepared the files offline.\n",
    "\n",
    "You can open [this URL](http://clima-dods.ictp.it/Users/tompkins/monsoons/data/) in a browser to see the file list. \n",
    "\n",
    "*Note that evaporation has been multiplied by -1 so that all terms are **positive** (negative) for atmospheric **sinks** (sources).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03492348-89c7-4bc8-a4ca-ce8bbe8b823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's just plot the moisture flux convergence. \n",
    "#\n",
    "def get_file(var,year):\n",
    "    file=\"http://clima-dods.ictp.it/Users/tompkins/monsoons/data/\"+var+\"_\"+str(year)+\"_asia_sn10_30_we60_100.nc\"\n",
    "    url = (file+'#mode=bytes')\n",
    "    dset = Dataset(url)\n",
    "    return(dset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0165df17-c6bb-480f-87e3-78a91db6e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the getting of data here to speed things up, \n",
    "# otherwise need to read in everytime we plot. \n",
    "# lets read into a dictory or a list of numpy arrays\n",
    "def get_data(dlist,var,fldname,sf=1,year=2000):\n",
    "    ds=get_file(var,year)\n",
    "    fld=np.squeeze(ds[fldname])*sf\n",
    "    dlist.append({\"var\":var,\"data\":fld,\"year\":year})\n",
    "    return dlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7233d86-0fa6-49a9-8450-c431793724c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fldnames=[\"tp\",\"e\",\"vimd\"]\n",
    "vars=[\"prec\",\"evap\",\"vimd\"]\n",
    "sf=[1,-1,1]\n",
    "dlist=[]\n",
    "year=2000\n",
    "\n",
    "#\n",
    "# Cycle through the fields and add each dataset as a dictionary to the list\n",
    "# \n",
    "for ivar,var in enumerate(vars):\n",
    "    dlist=get_data(dlist,vars[ivar],fldnames[ivar],sf=sf[ivar],year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ea3c3-8f17-4e19-97bc-3c842b25b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a simple line plot for the 3 styles\n",
    "def plotyear(dlist):\n",
    "    fig,ax = plt.subplots()\n",
    "\n",
    "    # hard wired \n",
    "    lstyles=[\"dashed\",\"solid\",\"solid\"]\n",
    "    lwidths=[2,1,1]\n",
    "    lcols=[\"grey\",\"grey\",\"black\"]\n",
    "    tick_spacing=20\n",
    "    \n",
    "    # fudge to correct labels to something nicer\n",
    "    labels={\"evap\":\"evaporation\",\"prec\":\"precipitation\",\"vimd\":\"MFC\"}\n",
    "\n",
    "    for ivar,var in enumerate(dlist):\n",
    "        ax.plot(var[\"data\"],\n",
    "                linestyle=lstyles[ivar],\n",
    "                linewidth=lwidths[ivar],\n",
    "                color=lcols[ivar],label=labels[var[\"var\"]])\n",
    "        break\n",
    "    ax.set_xlabel(\"day of year\")\n",
    "    ax.set_ylabel(\"(mm/day)\")\n",
    "    ax.set_title(\"year \"+str(var[\"year\"]))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "    plt.xticks(rotation=-45)\n",
    "    ax.xaxis.grid(linestyle=\"dotted\") # vertical lines\n",
    "    ax.legend()\n",
    "    plt.savefig(\"precip.jpg\",bbox_inches='tight',dpi=300)\n",
    "    return(fig,ax)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107c231-efff-4e2f-acb4-0caf1a2a7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plotyear(dlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489dabe-9809-4c1d-a72b-ea3735d5a0b7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## **Discussion**\n",
    "\n",
    "Break out into groups and quickly discuss these questions.\n",
    "\n",
    "- Does the plot based on ERA5 resemble the paper plot using MERRA/GPCP?\n",
    "- Can you think of any issues with using reanalysis for the budget calculations?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126100f-fed6-41a0-997b-7c4a73896852",
   "metadata": {},
   "source": [
    "## **WB16 onset definition**\n",
    "\n",
    "WB16 noted that the precipitation and divergence were quite noisy fields, making it difficult to use them to define a threshold for monsoon onset.  This is why often you will find onset definitions have a lot of \"bolt-ons\", that is, *\"it needs to rain at least X much, for Y consecutive days and... and... \"*\n",
    "\n",
    "WB16 thus decided to use the **cumulative** water budget for the onset, which in fact is inspired by some onset definitions that are based on cumulative precipitation.  This is the origin of the **red line** in panel a above, which was labled CMFC, which in turn stood for *Cumulative Moisture Flux Convergence*.  Let's take a look at this.  The VIMD parameter is simply summed using the function \n",
    "\n",
    "**cdo timcumsum in.nc out.nc**\n",
    "\n",
    "We've already calculated this for you, so let's just add it to the graph!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73663144-4529-4a5f-8a5b-6d76af79f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's get the cmfc, only one field so we we extract \n",
    "# it from the list and only keep the data\n",
    "cmfc=get_data([],var=\"cum_vimd\",fldname=\"vimd\",year=year)[0][\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce22de-3a7d-4770-b390-ac2e4743eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plotyear(dlist)\n",
    "\n",
    "# add CMFC on rh y axis\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(cmfc,label=\"CMFC\",color=\"red\")\n",
    "ax.set_xlabel(\"Day of Year\")\n",
    "ax2.set_ylabel(\"CMFC (mm)\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3487ac-ea37-430b-ad01-7bb5645472ce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## **Discussion**\n",
    "\n",
    "- Can you think of a way to use the cumulative moisture divergence instead ? How would this compare to your earlier estimate using the precipitation only?\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393a391-7274-4ef7-892d-367d52c7c872",
   "metadata": {},
   "source": [
    "WB16 suggested that the minimum of CMFC was a good metric of the monsoon onset; this is the point when the atmospheric moisture budget flips from net **export** to net **import** of water vapor in the broad monsoon region, again assuming negligible storage!\n",
    "\n",
    "Now it remains to find a simple algorithm to identify the minimum in CMFC.\n",
    "WB16 tackle this by using a method known as a [segmented regression](https://en.wikipedia.org/wiki/Segmented_regression) breakpoint analysis.  The idea is simple; one chooses an arbitrary point to split the time series, and two separate linear regression fits are made to the data prior to and after this point in time.  The mean square error is calculated between this fit and the original data, as a measure to how well this fit is.  By cycling through all possible breakpoints to identify the closest fit, we find the breakpoint.  Don't worry if you didn't understand this, we will go through it step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e65400-d0f0-4ad0-95c3-03ece43d62f7",
   "metadata": {},
   "source": [
    "To carry this out we will define some functions:\n",
    "\n",
    "- **Split**: simply splits a timeseries at an arbitrary given time point and returns the two segments.\n",
    "\n",
    "- **piecewise_polyfit**: fits the (linear) regression lines to the two portions (code can also perform higher order fits)\n",
    "\n",
    "- **find_changepoint**: Cycles through the series using the above functions to split at each point and chooses the \"best\" one.\n",
    "\n",
    "We start with the first two functions in this list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800ea19-2ed0-4ed1-8380-da27970fc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta #\n",
    "\n",
    "def split(x, n):\n",
    "    # split a series at point n\n",
    "    return x[:n], x[n:]\n",
    "\n",
    "def piecewise_polyfit(x, y, n, order=1):\n",
    "    y = np.ma.masked_array(y, np.isnan(y))\n",
    "\n",
    "    # split x and y at point n \n",
    "    x1, x2 = split(x, n)\n",
    "    y1, y2 = split(y, n)\n",
    "\n",
    "    # fit nth order (default=1) fit to two parts\n",
    "    p1 = np.ma.polyfit(x1, y1, order)\n",
    "    p2 = np.ma.polyfit(x2, y2, order)\n",
    "\n",
    "    # check for errors:\n",
    "    if np.isnan(p1).any() or np.isnan(p2).any():\n",
    "        raise ValueError('NaN for polyfit coeffs. Check data.')\n",
    "\n",
    "    # make the series based on the two piecewise fits\n",
    "    ypred1 = np.polyval(p1, x1)\n",
    "    ypred2 = np.polyval(p2, x2)\n",
    "    ypred = np.concatenate([ypred1, ypred2])\n",
    "\n",
    "    # calculate the Mean Square error of the piecewise fit to the\n",
    "    # original data, and return fit and RSS\n",
    "    rss = np.sum((y - ypred)**2)\n",
    "    return ypred, rss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50cf71-5ab5-4e44-8c00-5457aa38bd7a",
   "metadata": {},
   "source": [
    "Here we will show the method with an arbirtary split at day=140."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60416bc7-0f03-4022-94de-09b2e94c646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we define the number of time steps\n",
    "ntim=len(cmfc)\n",
    "# let's test an arbitrary break at day=140\n",
    "pt=140 \n",
    "x=list(range(ntim))\n",
    "ypred,rssval = piecewise_polyfit(x,cmfc,pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eac8e9-dedf-43e8-b949-c129adccff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plotyear(dlist)\n",
    "\n",
    "# add CMFC on rh y axis\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(cmfc,label=\"CMFC\",color=\"red\")\n",
    "ax.set_xlabel(\"Day of Year\")\n",
    "ax2.set_ylabel(\"CMFC (mm)\")\n",
    "ax2.legend()\n",
    "\n",
    "ax2.plot(ypred,color=\"green\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5aac3-fcb1-4bdb-8c8b-e2e015b020f2",
   "metadata": {},
   "source": [
    "Okay... well this worked okay... ish, but...\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**QUESTION**\n",
    "\n",
    "what do you think causes the poor fit for the second segment and what would be a quick easy fix?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962613fb-ad03-4560-9e6e-47292007c0d9",
   "metadata": {},
   "source": [
    "The issue is that we are fitting just two linear segments, and after around day 250-300 when the monsoon is coming to an end, the CMFC slope becomes negative again and  the fit is thus quite poor (there are actually 3 segments in other words if we consider calendar years)...  We could try to do a 3-part fit, but an easier solution is to truncate the series at day 250 or so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781db2a-62a3-49a1-9ebc-088d67b87bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff=250\n",
    "ypred_s,rssval = piecewise_polyfit(x[0:cutoff],cmfc[0:cutoff],pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e3840-48a2-47e0-8853-5299f0b21d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plotyear(dlist)\n",
    "\n",
    "# add CMFC on rh y axis\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(cmfc,label=\"CMFC\",color=\"red\")\n",
    "ax.set_xlabel(\"Day of Year\")\n",
    "ax2.set_ylabel(\"CMFC (mm)\")\n",
    "ax2.legend()\n",
    "\n",
    "ax2.plot(ypred_s,color=\"green\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b98fa8-8d9c-4f86-84de-40b2d50b6ef8",
   "metadata": {},
   "source": [
    "Okay, that's much better now!  So now let's cycle over the series and minimize the RSS to find the breakpoint.  For that we define the third routine listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce96c0-333a-4127-8f4a-5930ba7d8394",
   "metadata": {},
   "outputs": [],
   "source": [
    " def find_changepoint(x, y, order=1):\n",
    "    rss = []\n",
    "    \n",
    "    # swoop through the series, calculating RSS for each break point    \n",
    "    for n in range(2, len(x)- 2):\n",
    "        _, rssval = piecewise_polyfit(x, y, n, order)\n",
    "        rss.append(rssval)\n",
    "        \n",
    "    # x0 is the onset time from the minimum RSS\n",
    "    n0 = np.nanargmin(rss)\n",
    "    x0 = x[n0]\n",
    "    \n",
    "    ypred, _ = piecewise_polyfit(x, y, n0)\n",
    "    return x0, ypred, rss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31642b-2f07-45d4-af5e-c6e5cbb9fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0,ypred_best,rss=find_changepoint(x[0:cutoff],cmfc[0:cutoff])\n",
    "\n",
    "print (\" The onset date is predicted to be at day \",x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5407ce1-84c5-4d76-a166-63cd156988d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plotyear(dlist)\n",
    "\n",
    "\n",
    "# add CMFC on rh y axis\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(cmfc,label=\"CMFC\",color=\"red\")\n",
    "ax.set_xlabel(\"Day of Year\")\n",
    "ax2.set_ylabel(\"CMFC (mm)\")\n",
    "ax2.legend()\n",
    "\n",
    "ax2.plot(ypred_best,color=\"green\",linestyle=\":\",linewidth=2)\n",
    "\n",
    "# add vertical line at onset date\n",
    "ax.axvline(x0,color=\"blue\")\n",
    "ax.text(x=x0+3,y=12,s=\"Onset\",color=\"blue\",size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2ce04-34cc-4336-ac8f-dfdbc3fc87e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Discussion  \n",
    "\n",
    "- Why is the piece-wise segmentation regression better (clue = more \"robust\") than simply finding the minimum of the CMFC?\n",
    "- How does this breakpoint based onset compare to your initial estimate based on the precipitation timeseries? Is it earlier or later?  Why do you think this is?\n",
    "\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d0bc58-20de-4bca-bfe5-393edfedac62",
   "metadata": {},
   "source": [
    "# **Exercises**\n",
    "\n",
    "#### Basic:\n",
    "\n",
    "- The above exercise was conducted for the year 2000, which was the year used in fig 1 of WB16.  Repeat the above exercise for a few other years (include 2012 for example) so you get a feeling of the year to year variability in the time series.  Discuss within your groups, what are the robust features that stand out?  Are there any very abnormal years you can find?  Make a quick google search for exceptional years where the onset was particularly delayed or advanced, does this metric seem to agree?\n",
    "\n",
    "#### Intermediate:\n",
    "\n",
    "- You have seen how to calculate the onset for a given year, now loop over all years on line and calculate the onset for each year. Make a timeseries plot to show the interannual variability in the onset dates.\n",
    "- Earlier you tried to estimate an onset date simply using a precipitation threshold.  Try to make a timeseries of onset dates using this threshold and see how it compares to the CMFC one. \n",
    "\n",
    "#### Advanced:\n",
    "\n",
    "- For many forecast systems, such as the operational forecasts on the CDS, the divergence is not calculated and stored.  In Fig 1 of WB16 we saw that $\\frac{dW}{dt}$ is very limited.  You can calculate the storage term as a residual of $MFC$, $P$ and $E$.  Do this with the ERA data and convince yourself that the term is small. If you are convinced we can neglect it and assume no changes in atmospheric storage, then $MFC=P-E$.  Try out this approximation by recalculating the onset date using the approximation of the cumulative $P-E$. Make a scatter plot of  CMFC-based onset day and cumulative (P-E) onset day. What is the correlation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef59dac-d3a1-40ea-9bf7-165e0f73af60",
   "metadata": {},
   "source": [
    "\n",
    "# **Potential Projects**\n",
    "\n",
    "- Do you notice any trends in onset date? if you get the ERA5 retrievals working, try to go back to 1941 to the present\n",
    "\n",
    "- If you have your favourite onset definition in a datafile somewhere, try to read it in and make a comparison. \n",
    "\n",
    "- seasonal forecast?  Take a look at the ECMWF Sys 5 forecasts, do they have any skill in predicting onset day?\n",
    "\n",
    "- What about the CMIP6 ensemble, look at integrated P-E based onset and see if there are any trends that are clear by 2100?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
